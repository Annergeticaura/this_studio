{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bg4QC_Qk1rP",
        "outputId": "d07d00fd-fda1-495f-ccf8-9f2495923864"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.45.1-py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.14.0)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m856.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.24.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.41.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.4.26)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.25.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.45.1-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.45.1 watchdog-6.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BGoGkXpvk6DH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.layers import add, BatchNormalization, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input  # Or any other preprocessing based on your model\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVZnkQfKlBfv",
        "outputId": "a5f9fe2a-345b-49f7-c985-d917d4019d7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "import cv2\n",
        "import tempfile\n",
        "from tensorflow.keras.models import load_model\n",
        "from datetime import datetime\n",
        "from PIL import Image\n",
        "import time\n",
        "\n",
        "# Load models\n",
        "cnn_model = load_model(r\"InceptionV3Model.h5\")\n",
        "lstm_model = load_model(r\"AudioLSTMModel (1).h5\")\n",
        "\n",
        "# Constants\n",
        "FRAME_SIZE = (256, 256)\n",
        "MAX_FRAMES = 30\n",
        "MFCC_FEATURES = 13\n",
        "LSTM_INPUT_LENGTH = 130\n",
        "THRESHOLD = 0.5\n",
        "\n",
        "# Navigation\n",
        "st.set_page_config(page_title=\"Multimodal Deepfake Detector\", layout=\"wide\")\n",
        "st.sidebar.title(\"ğŸ” Navigation\")\n",
        "page = st.sidebar.radio(\"Go to\", [\"Home\", \"Upload & Analyze\", \"About\"])\n",
        "\n",
        "# Load images\n",
        "logo1 = Image.open(\"identity.png\")\n",
        "logo2 = Image.open(\"man.png\")\n",
        "\n",
        "# Toggle logo\n",
        "if \"logo_toggle\" not in st.session_state:\n",
        "    st.session_state.logo_toggle = False\n",
        "else:\n",
        "    st.session_state.logo_toggle = not st.session_state.logo_toggle  # Flip toggle each rerun\n",
        "\n",
        "# Select logo\n",
        "selected_logo = logo2 if st.session_state.logo_toggle else logo1\n",
        "st.sidebar.image(selected_logo, width=50)\n",
        "\n",
        "# Helper Functions\n",
        "def extract_frames(video_path, max_frames=MAX_FRAMES):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frames = []\n",
        "    frame_count = 0\n",
        "\n",
        "    while frame_count < max_frames:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        frame = cv2.resize(frame, FRAME_SIZE)\n",
        "        frame = frame / 255.0\n",
        "        frames.append(frame)\n",
        "        frame_count += 1\n",
        "\n",
        "    cap.release()\n",
        "    return np.array(frames)\n",
        "\n",
        "def extract_audio_mfcc(video_path, max_len=LSTM_INPUT_LENGTH):\n",
        "    import soundfile as sf\n",
        "    from pydub import AudioSegment\n",
        "\n",
        "    audio_path = video_path.replace(\".mp4\", \".wav\")\n",
        "\n",
        "    # Convert using ffmpeg-compatible method\n",
        "    sound = AudioSegment.from_file(video_path)\n",
        "    sound = sound.set_channels(1).set_frame_rate(16000)\n",
        "    sound.export(audio_path, format=\"wav\")\n",
        "\n",
        "    y, sr = librosa.load(audio_path, sr=16000)\n",
        "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=MFCC_FEATURES)\n",
        "    mfcc = mfcc.T\n",
        "\n",
        "    if mfcc.shape[0] > max_len:\n",
        "        mfcc = mfcc[:max_len]\n",
        "    else:\n",
        "        pad_width = max_len - mfcc.shape[0]\n",
        "        mfcc = np.pad(mfcc, ((0, pad_width), (0, 0)), mode='constant')\n",
        "\n",
        "    os.remove(audio_path)\n",
        "    return np.expand_dims(mfcc, axis=0)\n",
        "\n",
        "def predict_video_cnn(frames):\n",
        "    preds = cnn_model.predict(frames)\n",
        "    avg_pred = np.mean(preds)\n",
        "    return avg_pred\n",
        "\n",
        "def predict_audio_lstm(mfcc_features):\n",
        "    pred = lstm_model.predict(mfcc_features)[0][0]\n",
        "    return pred\n",
        "\n",
        "def aggregate_predictions(video_score, audio_score, threshold=THRESHOLD):\n",
        "    audio_fake = audio_score >= threshold\n",
        "    video_fake = video_score >= threshold\n",
        "\n",
        "    if audio_fake and video_fake:\n",
        "        verdict = \"ğŸŸ¥ Fake Audio Fake Video\"\n",
        "    elif audio_fake and not video_fake:\n",
        "        verdict = \"ğŸŸ¨ Fake Audio Real Video\"\n",
        "    elif not audio_fake and video_fake:\n",
        "        verdict = \"ğŸŸ§ Real Audio Fake Video\"\n",
        "    else:\n",
        "        verdict = \"ğŸŸ© Real Audio Real Video\"\n",
        "\n",
        "    return verdict, video_score, audio_score\n",
        "\n",
        "def save_report(verdict, video_score, audio_score):\n",
        "    now = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "    report = (\n",
        "        f\"Deepfake Detection Report\\n\"\n",
        "        f\"Date: {now}\\n\\n\"\n",
        "        f\"Final Verdict: {verdict}\\n\"\n",
        "        f\"Video Score: {video_score:.4f}\\n\"\n",
        "        f\"Audio Score: {audio_score:.4f}\\n\"\n",
        "    )\n",
        "    path = f\"deepfake_report_{now}.txt\"\n",
        "    with open(path, \"w\") as f:\n",
        "        f.write(report)\n",
        "    return path\n",
        "\n",
        "# Home Page\n",
        "if page == \"Home\":\n",
        "    st.title(\"ğŸ¬ Deepfake Detection System\")\n",
        "    st.markdown(\"\"\"\n",
        "    Welcome to the Deepfake Detection System using combined **Audio & Video analysis**.\n",
        "\n",
        "    This tool allows you to:\n",
        "    - Upload a video\n",
        "    - Analyze frames using a CNN (InceptionV3)\n",
        "    - Analyze audio using an LSTM\n",
        "    - Combine predictions to detect deepfakes\n",
        "\n",
        "    Navigate to the **Upload & Analyze** section to begin.\n",
        "    \"\"\")\n",
        "\n",
        "# Upload & Analyze\n",
        "elif page == \"Upload & Analyze\":\n",
        "    st.title(\"ğŸ“¤ Upload & Analyze\")\n",
        "\n",
        "    uploaded_file = st.file_uploader(\"Upload a video file\", type=[\"mp4\", \"avi\", \"mov\"])\n",
        "\n",
        "    if uploaded_file is not None:\n",
        "        st.video(uploaded_file)\n",
        "\n",
        "        with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as tmp:\n",
        "            tmp.write(uploaded_file.read())\n",
        "            tmp_path = tmp.name\n",
        "\n",
        "        st.info(\"Extracting frames and audio...\")\n",
        "        frames = extract_frames(tmp_path)\n",
        "        mfcc = extract_audio_mfcc(tmp_path)\n",
        "\n",
        "        st.success(f\"Extracted {len(frames)} frames and audio MFCCs.\")\n",
        "\n",
        "        st.info(\"Running predictions...\")\n",
        "        video_score = predict_video_cnn(frames)\n",
        "        audio_score = predict_audio_lstm(mfcc)\n",
        "\n",
        "        verdict, video_score, audio_score = aggregate_predictions(video_score, audio_score)\n",
        "\n",
        "        st.subheader(\"ğŸ§  Results\")\n",
        "        st.write(f\"**Final Verdict:** {verdict}\")\n",
        "        st.write(f\"**Video Fake Score:** {video_score:.2%}\")\n",
        "        st.write(f\"**Audio Fake Score:** {audio_score:.2%}\")\n",
        "\n",
        "        # Report Download\n",
        "        report_path = save_report(verdict, video_score, audio_score)\n",
        "        with open(report_path, \"rb\") as file:\n",
        "            st.download_button(\"ğŸ“„ Download Report\", data=file, file_name=report_path, mime=\"text/plain\")\n",
        "\n",
        "\n",
        "\n",
        "# About Page\n",
        "elif page == \"About\":\n",
        "    st.title(\"â„¹ï¸ About This App\")\n",
        "    st.markdown(\"\"\"\n",
        "    This app is built using:\n",
        "    - **Streamlit** for UI\n",
        "    - **InceptionV3 CNN** model for video frame analysis trained on OpenForensics Dataset\n",
        "    - **LSTM model** for audio (MFCC) deepfake detection trained on DeepVoice Dataset\n",
        "\n",
        "    The dataset used includes real and manipulated videos, where either audio or video content has been altered.\n",
        "    \"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZfjoNqqljXQ",
        "outputId": "edf70506-c851-481c-c384-1376deb761e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0Kâ ™\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0K\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.83.219.139:8501\u001b[0m\n",
            "\u001b[0m\n",
            "your url is: https://early-baboons-play.loca.lt\n",
            "2025-06-12 16:13:19.843097: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1749744799.873986   10923 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1749744799.883294   10923 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-06-12 16:13:26.070953: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 689ms/step\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427ms/step\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7bf57741cea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7bf57741cea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7bf57741d760> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7bf57741d760> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440ms/step\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WWfX19gclox8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}